# âœˆï¸ US Airline Delay Prediction â€” MLOps Project

A complete **end-to-end MLOps pipeline** that predicts the number of flight delays in a month using structured airline data. This project integrates data ingestion, model training, hyperparameter tuning, evaluation and experiment tracking (MLflow) following modular and scalable MLOps practices.

---

## ğŸ” Dataset Description

> Monthly summary of how each airline performed at a specific airport, capturing delay statistics and their causes.

- **Target Column**: **`arr_del15`** â€” Number of flights delayed (arrival delay â‰¥ 15 minutes) for each **carrier-airport pair** in a given **month**.


## ğŸ“ Project Structure

```

US\_Airline/
â”œâ”€â”€ backend/         # FastAPI application for model serving via REST API
â”œâ”€â”€ ml/              # Core ML pipeline: training, evaluation, and inference logic
â”œâ”€â”€ prisma-db/       # PostgreSQL schema managed via Prisma ORM
â””â”€â”€ README.md

```

---

## ğŸ§­ Getting Started

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/GITHUBsumesh/US_Airline.git
cd US_Airline
```

### 2ï¸âƒ£ Setup the Python environment

```bash
conda create -n flight-full python=3.11 -y
conda activate flight-full
pip install -r requirements.txt
```

Or use the provided YAML:

```bash
conda env create -f environment.yaml
conda activate flight-full
```

### 3ï¸âƒ£ Start FastAPI server

```bash
uvicorn backend.app:app --reload
```

---

### ğŸ§¾ Sample Prediction Data
Use the sample test CSV for predictions:

ğŸ“‚[test_data](./ml/test_data/test_data.csv)

---


## ğŸ“ Folder Breakdown

### ğŸ“¦ `backend/` â€“ API Layer

```text
â”œâ”€â”€ db/             # SQLAlchemy configuration
â”œâ”€â”€ models/         # Pydantic and DB models
â”œâ”€â”€ routes/         # Train and Predict endpoints
â”œâ”€â”€ services/       # Business logic for pipeline handling
â”œâ”€â”€ templates/      # Jinja2 HTML templates
â””â”€â”€ utils/          # Adds ml path to sys, for backend access
```

### ğŸ§  `ml/` â€“ Machine Learning Core

```text
â”œâ”€â”€ src/                # Component-wise pipeline implementation
â”œâ”€â”€ data_schema/        # Schema for input dataset
â”œâ”€â”€ dataset/            # Raw dataset source
â”œâ”€â”€ final_model/        # Best trained model + preprocessor
â”œâ”€â”€ notebooks/          # EDA and development notebooks
â”œâ”€â”€ test_data/          # Sample test file for predictions
â””â”€â”€ prediction_output/  # CSV output of predictions
```

### ğŸ—ƒï¸ `prisma-db/` â€“ PostgreSQL Integration

```text
â”œâ”€â”€ prisma/             # DB schema and setup
```

---

## ğŸš€ API Endpoints

| Endpoint        | Method | Description                                     |
| --------------- | ------ | ----------------------------------------------- |
| `/api/train/`   | `GET`  | Triggers full training pipeline                 |
| `/api/predict/` | `POST` | Upload test `.csv` and return delay predictions |

---

## ğŸ” Pipeline Flow

### ğŸ”¹ Step 1: Data Ingestion

* Reads cleaned rows from PostgreSQL DB (excluding null `arr_del15`)
* Splits into `train.csv` and `test.csv` (80/20)
* Saves Data Ingestion Artifact

### ğŸ”¹ Step 2: Data Validation

* Drops irrelevant columns
* Validates schema and shape
* Generates **Data Drift Report**
* Saves validated CSVs and artifact

### ğŸ”¹ Step 3: Data Transformation

* Drops `arr_del15` during transformation
* For each model:

  * Builds a tailored `ColumnTransformer`

    * Imputes: Mean (numeric), Most Frequent (categorical)
    * Scales: `StandardScaler` for applicable models
    * Encodes:

      * One-Hot: `"carrier"` (21 unique values)
      * Ordinal: `"airport"` (353 unique values)
  * Saves transformed NumPy arrays and preprocessor

### ğŸ”¹ Step 4: Model Trainer

* Supports multiple regressors:

  * Linear, Ridge, Lasso, KNN, SVR, RandomForest, ExtraTrees, XGBoost, LightGBM, GradientBoosting, DNN, CatBoost
* Model-specific processing:

  * `CatBoost`: Works on raw strings, no encoding/scaling
  * `DNN`: Uses `RepeatedKFold`, early stopping
  * Others: Hyperparameter tuning via `RandomizedSearchCV`
* RÂ² Score is used to evaluate each model
* Best model selected and retrained on full train set
* Model + preprocessor saved under `/final_model/`
* Metrics and model performance logged to Dagshub

---

## ğŸ§  Prediction Pipeline

1. Loads trained model and preprocessor (`final_model/`)
2. Accepts input CSV via API or CLI
3. Transforms the data using the saved pipeline
4. Returns predictions and logs them to DB + CSV

---

## ğŸ› ï¸ Execution Flow

| Script/File           | Purpose                                |
|-----------------------|----------------------------------------|
| `ml/push_data.py`     | Loads complete raw dataset into DB     |
| `backend/train.py`    | Triggers end-to-end training pipeline  |
| `backend/predict.py`  | Triggers prediction pipeline           |

---
## ğŸ§ª Technologies Used

- **ML/DL**: Scikit-Learn, CatBoost, XGBoost, Keras
- **MLOps**: MLflow, joblib, YAML-based config, Dagshub
- **Database**: PostgreSQL + Prisma ORM
- **Serving**: FastAPI (REST)
- **Logging**: Python logging + YAML reporting

---

## ğŸš§ Future Improvements

The following features are planned and under development:

* ğŸ³ **Dockerization**

  * Dockerize the entire application stack (FastAPI + PostgreSQL + Streamlit + MLflow)
  * Provide a `docker-compose.yml` for local setup

* ğŸŒ **Streamlit Web UI**

  * Interactive front-end for model training and CSV-based prediction
  * Include visualizations for model performance and data exploration

---

## âœ… How to Contribute

* [ ] Fork the repository
* [ ] Open issues for bugs or enhancements
* [ ] Submit PRs with clear commits and test cases

---

## ğŸ“Œ Author

**Sumesh**
*Engineering Student | MLOps & Fullstack Enthusiast*

ğŸ“§ [LinkedIn](https://linkedin.com/in/sumesh-ranjan-majee-yokoso)
ğŸ“‚ [GitHub](https://github.com/GITHUBsumesh)

---
